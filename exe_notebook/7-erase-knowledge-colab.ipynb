{"cells":[{"cell_type":"markdown","metadata":{"id":"SE5B8NHXAc4i"},"source":["Thesis implementation [Knowledge Neurons in Pretrained Transformers](https://github.com/Thaifitus/knowledge-neurons-thesis.git) execution."]},{"cell_type":"markdown","metadata":{"id":"kvhaRbXZh6J4"},"source":["# Clone repository"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10699,"status":"ok","timestamp":1723613431485,"user":{"displayName":"Thái Nguyễn Trương Hoàng","userId":"03111733856241861520"},"user_tz":-420},"id":"msFUAixv94Mc","outputId":"67a4e84d-ce11-4806-8c52-21df3b24e201"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'determining_and_erasing_kns_in_transformer_thesis'...\n","remote: Enumerating objects: 456, done.\u001b[K\n","remote: Counting objects: 100% (84/84), done.\u001b[K\n","remote: Compressing objects: 100% (66/66), done.\u001b[K\n","remote: Total 456 (delta 38), reused 35 (delta 18), pack-reused 372 (from 1)\u001b[K\n","Receiving objects: 100% (456/456), 95.02 MiB | 13.68 MiB/s, done.\n","Resolving deltas: 100% (219/219), done.\n","Updating files: 100% (181/181), done.\n"]}],"source":["'''\n","git clone specified branch.\n","'''\n","\n","!git clone --branch temp_branch https://github.com/Thaifitus/determining_and_erasing_kns_in_transformer_thesis.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1723613431485,"user":{"displayName":"Thái Nguyễn Trương Hoàng","userId":"03111733856241861520"},"user_tz":-420},"id":"Al6Mn6ZONSYm","outputId":"8da2c0ca-dac5-407e-d88f-fcf25bb52bdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/determining_and_erasing_kns_in_transformer_thesis/src\n"]}],"source":["'''\n","cd if already has the repository.\n","'''\n","\n","%cd /content/determining_and_erasing_kns_in_transformer_thesis/src"]},{"cell_type":"markdown","metadata":{"id":"RH3ks_Eah6KA"},"source":["# Install packages"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14407,"status":"ok","timestamp":1723613445889,"user":{"displayName":"Thái Nguyễn Trương Hoàng","userId":"03111733856241861520"},"user_tz":-420},"id":"PAsbQdEb-wUl","outputId":"b7520194-7ca7-4f96-d230-f063f92bb782"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jsonlines\n","  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n","Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-4.0.0\n","Collecting transformers==4.20.0\n","  Downloading transformers-4.20.0-py3-none-any.whl.metadata (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (0.23.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (2.32.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.20.0)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.0) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.20.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.20.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.20.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.20.0) (2024.7.4)\n","Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.42.4\n","    Uninstalling transformers-4.42.4:\n","      Successfully uninstalled transformers-4.42.4\n","Successfully installed tokenizers-0.12.1 transformers-4.20.0\n"]}],"source":["!pip install jsonlines\n","!pip install transformers==4.20.0"]},{"cell_type":"markdown","metadata":{"id":"crEAnsxHGID9"},"source":["# /src/7_run_erase.sh"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b10zS3FrlBga","outputId":"2cee2e5f-13d9-4af0-d215-908fafc19b88","executionInfo":{"status":"ok","timestamp":1723617678509,"user_tz":-420,"elapsed":4232625,"user":{"displayName":"Thái Nguyễn Trương Hoàng","userId":"03111733856241861520"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["08/14/2024 05:30:57 - INFO - __main__ -   device: cuda:0 n_gpu: 1, distributed training: False\n","Downloading: 100% 208k/208k [00:00<00:00, 39.0MB/s]\n","Downloading: 100% 49.0/49.0 [00:00<00:00, 292kB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 3.59MB/s]\n","08/14/2024 05:30:59 - INFO - __main__ -   ***** CUDA.empty_cache() *****\n","evaluating P27...\n","[('10@1169', 628), ('10@1435', 152), ('10@1808', 95), ('9@1738', 94), ('10@400', 92), ('11@2876', 90), ('11@2680', 76), ('10@1390', 64), ('9@369', 56), ('11@112', 54), ('10@1845', 50), ('6@251', 49), ('11@1588', 40), ('11@41', 39), ('8@2589', 38), ('9@2556', 38), ('8@2645', 37), ('9@866', 37), ('5@3064', 36), ('10@1607', 35), ('10@2253', 35), ('9@1944', 31), ('10@1692', 31), ('9@1345', 29), ('11@1040', 29), ('9@14', 28), ('10@2450', 28), ('7@2039', 26), ('9@643', 25), ('9@710', 25), ('11@1224', 23), ('8@488', 22), ('11@1754', 21), ('7@2831', 20), ('11@1761', 20), ('10@1885', 19), ('8@1809', 19), ('2@908', 18), ('10@2963', 17), ('8@1896', 17), ('9@318', 16), ('8@2367', 16), ('10@3019', 16), ('0@1259', 15), ('8@2171', 15), ('10@1248', 14), ('9@2914', 14), ('10@1565', 14), ('9@681', 12), ('10@1667', 11)]\n","Downloading: 100% 386M/386M [01:24<00:00, 4.79MB/s]\n","08/14/2024 05:32:25 - INFO - custom_bert -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at /root/.cache/huggingface/transformers/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n","08/14/2024 05:32:25 - INFO - custom_bert -   extracting archive file /root/.cache/huggingface/transformers/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmpn4exhjyx\n","08/14/2024 05:32:29 - INFO - custom_bert -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","08/14/2024 05:32:32 - INFO - custom_bert -   Weights from pretrained model not used in BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","\n","erasing -- kn_num: 50\n","\n","***** P27 erased. Costing time: 4132.1545 seconds *****\n","======================================== P27 ===========================================\n","erased accuracy: 0.2687\n","# Kneurons: 50\n","erased ppl: 43.6\n","(for other) erased accuracy: 0.2261\n","(for other) erased ppl: 148.3\n"]}],"source":["!bash 7_run_erase_ig.sh P106"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","toc_visible":true,"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30635,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}